{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [파이🌞] 정기세션 3주차  과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 다음 문장이 맞으면 T, 틀리면 F로 표시하시오.\n",
    "1. 대부분이 Positive이고 Negative한 데이터가 일부일 경우 성능 지표로 ROC-AUC보다는 정확도가 더 적합하다. (　)\n",
    "2. ID, 주민번호, 이름과 같이 단순 식별자 피처는 데이터 분석에 불필요하므로 드롭하는 게 좋다. (　)\n",
    "3. LightGBM이 XGBoost보다 학습을 하는데 시간이 덜 걸린다. (　)\n",
    "4. 오버샘플링 시 제대로된 학습을 위해 데이터 증식시 동일한 데이터를 복제하는 방법으로 증식시킨다. (　)\n",
    "5. 스태킹 기법으로 예측을 할시 항상 개별 모델보다 성능이 좋아진다. (　)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 다음 빈칸을 채우시오.\n",
    "1. 지도 학습에서 극단적으로 불균현항 레이블 값 분포를 갖고 있을 때 적은 데이터 세트를 증식하는 (　　　　) 방법을 사용하면 성능을 높일 수 있다.\n",
    "2. (　　　　)는 적은 데이터 세트에 있는 개별 데이터들의 (　　　　)를 찾아서 K개의 이웃들의 차이를 일정 값으로 만들어서 기존 데이터와 약간 차이가 나는 새로운 데이터를 생성하는 방식이다.\n",
    "3. (　　　　)은 개별 알고리즘의 예측 결과 데이터 세트를 최종적인 메타 데이터 세트로 만들어 별도의 ML알고리즘으로 치종 학습을 수행하고 테스트 데이터로 다시 최종 예측을 하는 방식이다.\n",
    "4. 기본 스태킹 모델의 경우 테스트용 레이블 데이터 세트를 기반으로 학습을 하기에 (　　　　) 문제를 발생시킬 수 있으며 이를 해결 하기 위해 (　　　　)으로 학습용 스태킹 데이터와 테스트용 스태킹 데이터로 만든 뒤 이것으로 학습과 예측을 하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost와 LightGBM 중 어느 것이 빠른지 비교해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "\n",
    "cust_df = pd.read_csv(\"./train_santander.csv\",encoding='latin-1')\n",
    "print('dataset shape:', cust_df.shape)\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df['var3'].replace(-999999,2, inplace=True)\n",
    "cust_df.drop('ID',axis=1 , inplace=True)\n",
    "\n",
    "X_features = cust_df.iloc[:, :-1]\n",
    "y_labels = cust_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels,\n",
    "                                                    test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. XGBoost로 학습을 할 경우 걸린 시간을 적으시오.\n",
    "XGBoost로 학습했을 때 걸린 시간 : (　　　　)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 시작 시간을 설정하는 코드를 적으시오.\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=500, random_state=156)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train, early_stopping_rounds=100,\n",
    "            eval_metric=\"auc\", eval_set=[(X_train, y_train), (X_test, y_test)])\n",
    "\n",
    "# 걸린 시간을 계산하는 코드를 적으시오.\n",
    "\n",
    "print('XGBoost 수행 시간 : {0:.1f}'.format(xgb_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. LightGBM으로 학습을 할 경우 걸린 시간을 적으시오.\n",
    "LightGBM으로 학습했을 때 걸린 시간 : (　　　　)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 시작 시간을 설정하는 코드를 적으시오.\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=500)\n",
    "\n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_clf.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"auc\", eval_set=evals,\n",
    "                verbose=True)\n",
    "\n",
    "# 걸린 시간을 계산하는 코드를 적으시오.\n",
    "\n",
    "print('XGBoost 수행 시간 : {0:.1f}'.format(lgbm_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. XGBoost와 LightGBM 중 어느 것이 더 빠른지 쓰시오.\n",
    "(　　　　　　　　)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 다음은 신용카드 데이터 세트이다. 이 데이터 세트의 이상치를 제거했을 때와 SMOTE방식을 사용했을 때 정밀도와 재현율 수치가 변화하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "card_df = pd.read_csv('./creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.drop('Time', axis=1, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_dataset(df=None):\n",
    "    df_copy = get_preprocessed_df(df)\n",
    "    X_features = df_copy.iloc[:, :-1]\n",
    "    y_target = df_copy.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_features, y_target, test_size=0.3, random_state=0, stratify=y_target)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    \n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_train_eval(model, ftr_train=None, ftr_test=None, tgt_train=None, tgt_test=None):\n",
    "    model.fit(ftr_train, tgt_train)\n",
    "    pred = model.predict(ftr_test)\n",
    "    get_clf_eval(tgt_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "print('='*15+' 데이터 가공 전의 LightGBM 성능 지표 '+'='*15)\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_outlier(df=None, column=None, weight=1.5):\n",
    "    fraud = df[df['Class']==1][column]\n",
    "    quantile_25 = np.percentile(fraud.values, 25)\n",
    "    quantile_75 = np.percentile(fraud.values, 75)\n",
    "    boundary = quantile_75 - quantile_25\n",
    "    iqr_weight = boundary * weight\n",
    "    lowest_val = quantile_25 - iqr_weight\n",
    "    highest_val = quantile_75 + iqr_weight\n",
    "    \n",
    "    outlier_index = fraud[(fraud < lowest_val) | (fraud > highest_val)].index\n",
    "    return outlier_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_index = get_outlier(df=card_df, column='V14', weight=1.5)\n",
    "print('이상치 데이터 인덱스:', outlier_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    amount_n = np.log1p(df_copy['Amount'])\n",
    "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
    "    df_copy.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "    outlier_index = get_outlier(df=df_copy, column='V14', weight=1.5)\n",
    "    df_copy.drop(outlier_index, axis=0, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*15+' V14의 이상치 제거 후 LightGBM 성능 지표 '+'='*15)\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. V14의 이상치 제거에 대하여 다음의 물음에 답하시오.\n",
    "1. V14의 이상치를 제거한 후 가공 전 데이터와 비교했을 때 정밀도는 어떻게 되었는가?\n",
    "2. V14의 이상치를 제거한 후 가공 전 데이터와 비교했을 때 재현율는 어떻게 되었는가?\n",
    "3. 왜 그렇게 변했는지 서술하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_over, y_train_over = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "print('='*15+' SMOTE방법 사용 후 성능 지표 '+'='*15)\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train_over, ftr_test=X_test,\n",
    "                  tgt_train=y_train_over, tgt_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. SMOTE 방식을 사용한 후에 대하여 다음의 물음에 답하시오.\n",
    "1. SMOTE 방식을 사용한 후 가공 전 데이터와 비교했을 때 정밀도는 어떻게 되었는가?\n",
    "2. SMOTE 방식을 사용한 후 가공 전 데이터와 비교했을 때 재현율는 어떻게 되었는가?\n",
    "3. 왜 그렇게 변했는지 서술하시오."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
