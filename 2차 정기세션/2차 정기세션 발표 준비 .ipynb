{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-19031c42665f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-27-19031c42665f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    import os os.getcwd()\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# 파이썬 버전 바뀌면 코드 오류날 수 있다는 경고 표시 무시하는 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0], 1)) #Survived를 0으로 일단 채운다\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1: #남자\n",
    "                pred[i] = 0 #죽음\n",
    "            else:\n",
    "                pred[i] = 1 #살았다\n",
    "        return pred\n",
    "    \n",
    "    \n",
    "# 타이타닉데이터 분류 모델 생성, 정확도로만 성능 예측하면 모델 성능 왜곡될 수도 있다는 걸 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df\n",
    "\n",
    "# 2장에서 데이터 전처리 한거 가져와야 다음 코드가 오류가 안남. 타이타닉 데이터 전처리하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pwd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-25abbb8909b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpwd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# 현재 이 파일 위치 알 수 있는 코드\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pwd' is not defined"
     ]
    }
   ],
   "source": [
    "pwd\n",
    "# 현재 이 파일 위치 알 수 있는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "titanic_df = pd.read_csv('.\\\\train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df) # 바로 위 셀에서 언급한 데이터 전처리 코드\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는: 0.7877\n"
     ]
    }
   ],
   "source": [
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test, mypredictions)))\n",
    "\n",
    "# 아무것도 안하고 그냥 남자면 죽고 여자면 사는 분류모델인데도 정확도가 높음 -> 이진분류에서 정확도로는 성능 예측하기가 어려움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "# df = pd.DataFrame(data=digits.data)\n",
    "# df['label'] = digits.target\n",
    "# df.head()\n",
    "# 데이터가 뭘로 구성되어 있는지 궁금해서 만들어봄\n",
    "\n",
    "y = (digits.target == 7).astype(int) \n",
    "# (digits.target == 7)는 boolean(논리자료형, 참과 거짓 구분) int 씌웠을 때 True면 1이고 False면 0 따라서 7이면 1이 됨\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=2019)\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "accuracy_score(y_test, fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오차행렬(Confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[408,   0],\n",
       "       [ 42,   0]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, fakepred)\n",
    "# [7이 아닌 것, 7이 아닌데 7로 예측]\n",
    "# [7인데 7이 아니라고 예측, 7인 것]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정밀도(Precision)와 재현율(Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정밀도 = TP / TP + FP -> N인데 P로 예측되면 곤란할 때 중요지표 ex) 스팸메일(스팸메일 아닌데 스팸으로 분류되면 곤란)\n",
    "# 재현율 = TP / TP + FN (민감도 또는 TPR) -> P인데 N으로 예측되면 곤란할 때 중요지표 ex) 사기, 병진단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "titanic_df = pd.read_csv('train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df) # 바로 위 셀에서 언급한 데이터 전처리 코드\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[97 19]\n",
      " [18 45]]\n",
      "정확도: 0.7933, 정밀도: 0.7031, 재현율: 0.7143\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정밀도/재현율 트레이드 오프\n",
    "# 결정 임계값(Threshold)을 조정하면 정밀도와 재현율 조정가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 shape: (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.30487037 0.69512963]\n",
      " [0.49103292 0.50896708]\n",
      " [0.78772566 0.21227434]]\n",
      "두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.30487037 0.69512963 1.        ]\n",
      " [0.49103292 0.50896708 1.        ]\n",
      " [0.78772566 0.21227434 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test) #predict_proba는 이진 분류에서 두 개 확률을 다 보여줌\n",
    "pred = lr_clf.predict(X_test)\n",
    "print('pred_proba()결과 shape: {}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3]) # numpy는 head 안됨\n",
    "\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1, 1)], axis=1) #(-1, 1)은 2차원으로 변환. 컬럼 1개인 시리즈처럼 됨\n",
    "print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n', pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold - Binarizer 클래스 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[1, -1, 2],\n",
    "    [2, 0, 0],\n",
    "    [0, 1.1, 1.2]]\n",
    "\n",
    "binarizer = Binarizer(threshold=1.1)\n",
    "print(binarizer.fit_transform(X))\n",
    "\n",
    "# Binarizer(threshold=0.0, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[97 19]\n",
      " [18 45]]\n",
      "정확도: 0.7933, 정밀도: 0.7031, 재현율: 0.7143\n"
     ]
    }
   ],
   "source": [
    "custom_threshold = 0.5\n",
    "pred_proba_1 = pred_proba[:, 1].reshape(-1, 1) #살아 있을 확률 선택, 2차원 데이터로 변환 proba 반환값의 두 번째 칼럼(Positive 클래스 칼럼) 하나만 추출해서 Binarize 적용\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) #임계값 설정:0.5, 임의로 변경 가능, fit은 아무 것도 안하고 estimator 반환\n",
    "custom_predict = binarizer.transform(pred_proba_1) #임계값 적용해서 변환한 것\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)\n",
    "\n",
    "#임계값이 낮아질 수록 재현율이 올라가고 정밀도가 떨어진다. 정밀도는 FP 들어가니까! 임계값이 낮아진다는 뜻은 P가 많아진다는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#임곗값: 0.4\n",
      "오차 행렬\n",
      "[[92 24]\n",
      " [17 46]]\n",
      "정확도: 0.7709, 정밀도: 0.6571, 재현율: 0.7302\n",
      "#임곗값: 0.45\n",
      "오차 행렬\n",
      "[[96 20]\n",
      " [18 45]]\n",
      "정확도: 0.7877, 정밀도: 0.6923, 재현율: 0.7143\n",
      "#임곗값: 0.5\n",
      "오차 행렬\n",
      "[[97 19]\n",
      " [18 45]]\n",
      "정확도: 0.7933, 정밀도: 0.7031, 재현율: 0.7143\n",
      "#임곗값: 0.55\n",
      "오차 행렬\n",
      "[[101  15]\n",
      " [ 19  44]]\n",
      "정확도: 0.8101, 정밀도: 0.7458, 재현율: 0.6984\n",
      "#임곗값: 0.6\n",
      "오차 행렬\n",
      "[[102  14]\n",
      " [ 21  42]]\n",
      "정확도: 0.8045, 정밀도: 0.7500, 재현율: 0.6667\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "\n",
    "def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('#임곗값:', custom_threshold)\n",
    "        get_clf_eval(y_test, custom_predict)\n",
    "        \n",
    "get_eval_by_threshold(y_test, pred_proba[:, 1].reshape(-1, 1), thresholds)\n",
    "\n",
    "# 임계값에 따른 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  15  30  45  60  75  90 105 120 135 150]\n",
      "[0.0976 0.1171 0.1331 0.1462 0.1717 0.2196 0.3834 0.5982 0.6575 0.7327\n",
      " 0.9068]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1) \n",
    "# precision_recall_curve() 는 일반적으로 0.11~0.95 정도의 임계값, 정밀도 및 재현율 값을 담은 넘파이 ndarray 반환\n",
    "thr_index = np.arange(0, thresholds.shape[0], 15) #0부터 shape=148까지 15step으로 추출\n",
    "print(thr_index)\n",
    "print(np.round(thresholds[thr_index], 4)) # 샘플 임계값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.377 0.409 0.44  0.483 0.529 0.598 0.639 0.754 0.805 0.885 1.   ]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(precisions[thr_index], 3))\n",
    "\n",
    "# 임계값에 따른 정밀도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.    0.968 0.937 0.905 0.857 0.825 0.73  0.683 0.524 0.365 0.175]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(recalls[thr_index], 3))\n",
    "\n",
    "# 임계값에 따른 재현율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 스코어(F1 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2*(precision*recall/precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 스코어: 0.7087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, pred)\n",
    "print('F1 스코어: {0:.4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#임곗값: 0.4\n",
      "오차 행렬\n",
      "[[92 24]\n",
      " [17 46]]\n",
      "정확도: 0.7709, 정밀도: 0.6571, 재현율: 0.7302, f1: 0.6917\n",
      "#임곗값: 0.45\n",
      "오차 행렬\n",
      "[[96 20]\n",
      " [18 45]]\n",
      "정확도: 0.7877, 정밀도: 0.6923, 재현율: 0.7143, f1: 0.7031\n",
      "#임곗값: 0.5\n",
      "오차 행렬\n",
      "[[97 19]\n",
      " [18 45]]\n",
      "정확도: 0.7933, 정밀도: 0.7031, 재현율: 0.7143, f1: 0.7087\n",
      "#임곗값: 0.55\n",
      "오차 행렬\n",
      "[[101  15]\n",
      " [ 19  44]]\n",
      "정확도: 0.8101, 정밀도: 0.7458, 재현율: 0.6984, f1: 0.7213\n",
      "#임곗값: 0.6\n",
      "오차 행렬\n",
      "[[102  14]\n",
      " [ 21  42]]\n",
      "정확도: 0.8045, 정밀도: 0.7500, 재현율: 0.6667, f1: 0.7059\n"
     ]
    }
   ],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, f1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "\n",
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "\n",
    "def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('#임곗값:', custom_threshold)\n",
    "        get_clf_eval(y_test, custom_predict)\n",
    "        \n",
    "get_eval_by_threshold(y_test, pred_proba[:, 1].reshape(-1, 1), thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC 곡선과 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPR이 변할 때 TPR의 변화를 나타내는 곡선\n",
    "# AUC 값이 1에 가까울 수록 좋은 수치\n",
    "# FPR이 0이 되려면 임계값 1, 1이 되려면 임계값 0\n",
    "# FPR = FP/FP+TN, 임계값 1이면 FP=0, 임계값 0이면 TN=0임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  5 10 15 20 25 30 35 40 45 50 55 60 65]\n",
      "[1.9582 0.7418 0.6981 0.6715 0.6173 0.5301 0.3453 0.2836 0.2015 0.1682\n",
      " 0.15   0.1382 0.1254 0.1028]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] # 레이블 값이 1일 때의 예측 확률을 추출\n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "thr_index = np.arange(0, thresholds.shape[0], 5)\n",
    "print(thr_index)\n",
    "print(np.round(thresholds[thr_index], 4)) #왜 1.96이 나올까? 이건 아직도 풀지 못함ㅠㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.95824177, 0.74175497, 0.69811098, 0.6715085 , 0.61731393,\n",
       "       0.53005577, 0.34528241, 0.28363138, 0.20149285, 0.16824744,\n",
       "       0.15001786, 0.13821828, 0.12540158, 0.10275819])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds[thr_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.34920635 0.42857143 0.49206349 0.66666667 0.71428571\n",
      " 0.74603175 0.79365079 0.82539683 0.87301587 0.88888889 0.93650794\n",
      " 0.95238095 0.98412698]\n",
      "[0.         0.01724138 0.03448276 0.06896552 0.12068966 0.13793103\n",
      " 0.24137931 0.25862069 0.36206897 0.42241379 0.51724138 0.5862069\n",
      " 0.69827586 0.85344828]\n"
     ]
    }
   ],
   "source": [
    "tprs[thr_index]\n",
    "print(tprs[thr_index])\n",
    "print(fprs[thr_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "        0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.03448276,\n",
       "        0.03448276, 0.04310345, 0.04310345, 0.06034483, 0.06034483,\n",
       "        0.06896552, 0.06896552, 0.06896552, 0.0862069 , 0.0862069 ,\n",
       "        0.12068966, 0.12068966, 0.12931034, 0.12931034, 0.13793103,\n",
       "        0.13793103, 0.19827586, 0.19827586, 0.23275862, 0.23275862,\n",
       "        0.24137931, 0.24137931, 0.25      , 0.25      , 0.25862069,\n",
       "        0.25862069, 0.26724138, 0.26724138, 0.28448276, 0.28448276,\n",
       "        0.36206897, 0.36206897, 0.37068966, 0.37068966, 0.42241379,\n",
       "        0.42241379, 0.43103448, 0.44827586, 0.47413793, 0.47413793,\n",
       "        0.51724138, 0.51724138, 0.56034483, 0.56034483, 0.5862069 ,\n",
       "        0.5862069 , 0.60344828, 0.62068966, 0.68103448, 0.68103448,\n",
       "        0.69827586, 0.69827586, 0.75862069, 0.78448276, 0.78448276,\n",
       "        0.85344828, 0.87068966, 0.89655172, 0.89655172, 1.        ]),\n",
       " array([0.        , 0.01587302, 0.33333333, 0.33333333, 0.34920635,\n",
       "        0.34920635, 0.36507937, 0.36507937, 0.41269841, 0.41269841,\n",
       "        0.42857143, 0.42857143, 0.44444444, 0.44444444, 0.49206349,\n",
       "        0.49206349, 0.53968254, 0.57142857, 0.57142857, 0.66666667,\n",
       "        0.66666667, 0.68253968, 0.68253968, 0.6984127 , 0.6984127 ,\n",
       "        0.71428571, 0.71428571, 0.73015873, 0.73015873, 0.74603175,\n",
       "        0.74603175, 0.76190476, 0.76190476, 0.77777778, 0.77777778,\n",
       "        0.79365079, 0.79365079, 0.80952381, 0.80952381, 0.82539683,\n",
       "        0.82539683, 0.84126984, 0.84126984, 0.85714286, 0.85714286,\n",
       "        0.87301587, 0.87301587, 0.87301587, 0.87301587, 0.88888889,\n",
       "        0.88888889, 0.9047619 , 0.9047619 , 0.92063492, 0.92063492,\n",
       "        0.93650794, 0.93650794, 0.93650794, 0.93650794, 0.95238095,\n",
       "        0.95238095, 0.96825397, 0.96825397, 0.96825397, 0.98412698,\n",
       "        0.98412698, 0.98412698, 0.98412698, 1.        , 1.        ]),\n",
       " array([1.95824177, 0.95824177, 0.74561013, 0.74319948, 0.74248934,\n",
       "        0.74175497, 0.73573316, 0.73274469, 0.71120484, 0.70297022,\n",
       "        0.69811098, 0.69804726, 0.69573357, 0.69253121, 0.68119244,\n",
       "        0.6715085 , 0.65086953, 0.64250712, 0.6374624 , 0.6281776 ,\n",
       "        0.61731393, 0.59817321, 0.59622963, 0.5590228 , 0.54365422,\n",
       "        0.53005577, 0.41054009, 0.40982846, 0.35210367, 0.34955992,\n",
       "        0.34528241, 0.32617797, 0.31941858, 0.29401396, 0.29096671,\n",
       "        0.28363138, 0.27755693, 0.27676815, 0.26802929, 0.24153053,\n",
       "        0.20149285, 0.19799126, 0.19781728, 0.19656266, 0.16915095,\n",
       "        0.16824744, 0.1661151 , 0.16580725, 0.16054766, 0.15900451,\n",
       "        0.15001786, 0.14633937, 0.14153056, 0.14087899, 0.13856092,\n",
       "        0.13821828, 0.13623476, 0.13572836, 0.13030031, 0.12901726,\n",
       "        0.12540158, 0.12299937, 0.11713009, 0.11707723, 0.11417319,\n",
       "        0.10275819, 0.1022496 , 0.09929774, 0.09761083, 0.05655079]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_curve(y_test, pred_proba_class1)\n",
    "\n",
    "# 할당하는 값이 궁금해서 넣어봄, 위에 precision_recall_curve랑 방식 비슷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprs, tprs, thresholds = roc_curve(y_test, pred_proba_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def roc_curve_plot(y_test, pred_proba_c1): \n",
    "    fprs, tprs, thresholds = roc_curve(y_test, pred_proba_c1)# 임계값에 따른 FDR, TPR 값을 반환받음.\n",
    "    \n",
    "    plt.plot(fprs, tprs, label='ROC') # ROC 곡선을 그래프 곡선으로 그림 (label은 선 이름)\n",
    "    plt.plot([0,1],[0,1], 'k--', label='Random') # 가운데 대각선 직선을 그림 (점선)\n",
    "    \n",
    "    # FPR X 축의 Scale을 0.1 단위로 선정하고 x축 y 축 선정 등등 해야하지만 귀찮아서 안했음\n",
    "    \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend()\n",
    "roc_curve_plot(y_test, pred_proba[:, 1\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.017, 0.034, 0.069, 0.121, 0.138, 0.241, 0.259, 0.362,\n",
       "       0.422, 0.517, 0.586, 0.698, 0.853])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(fprs[thr_index], 3)\n",
    "\n",
    "# fpr 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.349, 0.429, 0.492, 0.667, 0.714, 0.746, 0.794, 0.825,\n",
       "       0.873, 0.889, 0.937, 0.952, 0.984])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(tprs[thr_index], 3)\n",
    "\n",
    "# tpr 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pred = lr_clf.predict(X_test)\n",
    "roc_score = roc_auc_score(y_test, pred) # 가운데 대각선에서 멀어지고 왼쪽 상단 모서리 쪽으로 가파르게 곡선이이동할수록 \n",
    "                                        # 직사각형에 가까운 곡선이 되며 좋은 ROC AUC 성능 수치를 얻게 된다. (보통 0.5 이상)\n",
    "roc_score\n",
    "# ROC AUC 값"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
